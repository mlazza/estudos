{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma tradução livre de um kernel explicativo voltado a iniciantes em Data Science, extraído do site kaggle.com, construído pelo usuário LD Freeman. Fonte: https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "Obs: algumas partes foram adaptadas para ficar mais inteligíveis para o português e fazerem mais sentido no contexto da nossa língua. Versão para Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um modelo de Data Science: atingindo 99% de acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olá e bem-vindo ao Kaggle, a comunidade online de Datascience de aprendizado, compartilhamento, e competição. A maioria dos iniciantes ficam perdidos nesta área, porque eles caem dentro de uma abordagem de 'caixa preta', utilizando algoritmos e bibliotecas que eles não compreendem. Este tutorial vai dar a você 1-2 anos de vantagem sobre os seus colegas, mostrando um modelo que ensinará você como pensar como um Cientista de Dados vs o que pensar/codificar. Não apenas tornará você apto a participar de sua primeira competição, mas te habilitará a resolver qualquer problema que você venha a abordar. Eu coloco explicações claras, código limpo, e muitos links de recursos. Observação: Este Kernel ainda está em desenvolvimento. Então, verifique a parte \"Change Logs\" abaixo para conhecer os updates. E ainda, dá um like, faça o fork, e comente, e eu continuarei a desenvolver. Obrigado, e você pode ter uma sorte \"estatisticamente significante\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lista de Conteúdo:</h2>\n",
    "\n",
    "<h3>1 - Capítulo 1 - Como um Cientista de Dados vence a probabilidade</h3>\n",
    "<h3>2 - Capítulo 2 - Um padrão de Data Science - 'framework'</h3>\n",
    "<h3>3 - Capítulo 3 - Passo 1: Definir o problema e Passo 2: Reunir os dados</h3>\n",
    "<h3>4 - Capítulo 4 - Passo 3: Preparar os dados para Uso</h3>\n",
    "<h3>5 - Capítulo 5 - Os 4 C's do Tratamento de Dados: corrigir, completar, criar e converter</h3>\n",
    "<h3>6 - Capítulo 6 - Passo 4: Fazendo a Análise Exploratória de Dados com a Estatística</h3>\n",
    "<h3>7 - Capítulo 7 - Passo 5: O Modelo de Dados</h3>\n",
    "<h3>8 - Capítulo 8 - Avaliando a performancedo do Modelo</h3>\n",
    "<h3>9 - Capítulo 9 - Ajustando o Modelo com 'Hyper-Parameters'</h3>\n",
    "<h3>10 - Capítulo 10 - Ajustando o Modelo com ferramentas de seleção (feature selection)</h3>\n",
    "<h3>11 - Capítulo 11 - Passo 6: Validando e Implementando</h3>\n",
    "<h3>12 - Capítulo 12 - Conclusão e Passo 7: Otimizando e traçando estratégias</h3> \n",
    "<h3>13 - Change Log (Atualizações)</h3>\n",
    "<h3>14 - Créditos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como usar este Tutorial: Leia as explicações que estão neste Kernel e veja os links para ter acesso à documentação. O objetivo não é ensinar o 'como fazer', mas o 'por que fazer'. Se você não entender algo no código, a função 'print()' é a sua melhor amiga. Em programação, é OK tentar, falhar, e tentar novamente. Se você ficar com problemas, o Google é seu segundo melhor amigo, porque 99,99% do tempo, alguém já teve este mesmo problema/pergunta e já foi respondida pela comunidade. Se você já esgotou todos os recursos, a comunidade Kaggle via fóruns e comentários pode ajudar você também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como um Cientista de Dados vence a Probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É um problema clássico, prever os resultados de um evento binário. Em termos leigos isso significa que um evento tem dois resultados apenas: pode ou não pode ocorrer. Por exemplo, você pode ganhar ou perder, você pode passar ou não passar num teste, você foi aceito ou não foi aceito. Uma aplicação comum nos negócios é a questão de rotatividade e retenção de clientes. Outra aplicação costumeira é na análise da taxa de mortalidade ou de sobrevivência nos cuidados de emergência em saúde. Eventos Binários criam um interesse dinâmico, porque nós sabemos estatisticamente que um palpite aleatório dentro desses eventos tem uma chance de 50% de acerto, sem criar nenhum único algoritmo ou escrever nenhuma linha de código. Contudo, assim como a tecnologia dos corretores ortográficos, algumas vezes nós mesmos seres humanos podemos cometer alguns erros e ser tão 'inteligentes' a ponto de apostar e ter menos do que 50% de chances (coin flip). Neste kernel, eu utilizo a competição inicial sugerida pelo Kaggle que é o \"Titanic: Machine Learning from Disaster\", para levar o leitor através do uso dos modelos e instrumentos de Data Science para 'vencer a probabilidade'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um modelo de Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <h5>DEFINIR O PROBLEMA.</h5> \n",
    "Se Data Science, Big Data, Machine Learning, Análise Preditiva, Business Intelligence, ou qualquer outra estratégia é a solução, então qual é o problema? Como se diz, não coloque a carroça na frente dos cavalos. Problemas antes de requisitos, requisitos antes de soluções, soluções antes de design, e design antes da tecnologia. É muito frequente termos o impulso de pularmos as fases e ficarmos presos na tecnologia, na ferramenta, ou algortimo antes de determinar exatamente o problema que estamos querendo resolver.\n",
    "\n",
    "2. <h5>REUNIR OS DADOS.</h5> \n",
    "John Naisbitt escreveu em seu livro de 1984 \"Megatrends\": nós estamos \"se afogando em dados, ainda famintos por conhecimento.\". Então, atualmente, é provável, que um conjunto de dados (dataset) já exista em algum lugar, em algum formato. Ele pode ser externo ou interno, estruturado ou não-estruturado, estático ou transmitido, objetivo ou subjetivo, etc. Como se diz, você não precisa reinventar a roda, apenas saber onde encontrar estes dados. No próximo passo, nós iremos nos preocupar em transformar os dados brutos em dados limpos ('dirty data' to 'clean data').\n",
    "\n",
    "3. <h5>PREPARAR OS DADOS PARA USO.</h5> \n",
    "Este passo é geralmente conhecido como tratamento de dados, um processo necessário para transformar os dados brutos em dados que possam ser manipulados. O tratamento de dados inclui implementar arquitetura de dados para armazenar e processar, desenvolver padrões de governança para qualidade e controle, extração de dados (i.e. ETL e coleta de dados web), e limpeza de dados para identificar dados fora do padrão, perdidos, discrepantes, etc.\n",
    "\n",
    "4. <h5>FAZENDO A ANÁLISE EXPLORATÓRIA.</h5> \n",
    "Qualquer um que já tenha trabalhado com dados sabe: inputs ruins levam a outputs ruins (garbage-in, garbage-out (GIGO). Portanto, é importante utilizar da estatística descritiva e análise gráfica para encontrar potenciais problemas, padrões, classificações, correlações e comparações no conjunto de dados. Ainda, a categorização de dados (quantitativo x qualitativo) é também importante para entender e selecionar as hipóteses corretas ou o modelo de dados.\n",
    "\n",
    "5. <h5>O MODELO DE DADOS.</h5> \n",
    "Assim como a estatística descritiva e inferencial, a modelagem de dados pode também sumarizar os dados ou predizer possíveis resultados futuros. O seu conjunto de dados e resultados esperados irão determinar os algoritmos disponíveis a serem utilizados. É importante lembrar, algoritmos são ferramentas e não varinhas mágicas ou balas de prata. Você deve ser o mestre artesão que sabe como selecionar a ferramenta ideal para o trabalho a ser feito. Uma analogia poderia ser se você pedisse para alguém uma chave de fenda Philips, e ele te alcança a chave de fenda comum ou, pior, um martelo. Na melhor das hipóteses, isso poderia apenas ser uma má compreensão do que foi pedido. Na pior, isso poderia tornar o seu trabalho impossível de ser realizado. Esta é a mesma situação aplicada a modelagem de dados. O modelo errado pode levar a uma fraca performance e até a uma conclusão errada do seu trabalho.\n",
    "\n",
    "6. <h5>VALIDAÇÃO E IMPLEMENTAÇÃO DO MODELO DE DADOS.</h5> \n",
    "Depois de você treinar o seu modelo baseado num subconjunto de dados, é hora de testar o seu modelo. Isto ajuda a assegurar que você não extrapolou (generalizou demais) o seu modelo ou fez algo tão específico para o subconjunto apenas, o que faz que não seja tão exato quando aplicado/generalizado para outro subconjunto do mesmo conjunto de dados (dataset). Neste passo, nós determinamos se o nosso modelo 'overfit', 'generalize, ou 'underfit' o nosso dataset. Segue link para entender melhor estes últimos termos: https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "7. <h5>OTIMIZAÇÃO E TRAÇAR ESTRATÉGIAS.</h5> \n",
    "Este é o passo 'biônico', onde você repete o processo para torná-lo melhor... mais robusto... e mais rápido do que antes. Como cientista de dados, a sua estratégia poderia ser a de terceirizar as operações de desenvolvimento e da aplicação, assim você pode ter mais tempo para focar nas recomendações e no design. Quando você conseguir construir o seu próprio jeito de fazer as coisas e criar sua própria metodologia, isto se tornará sua moeda de troca para novos trabalhos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 1: Definir o Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este projeto, com a declaração do problema que nos é dado de mão beijada, desenvolver um algoritmo para prever os sobreviventes do Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo do Projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O naufrágio do RMS Titanic é um dos mais famosos acidentes navais da história. Em 15 de abril de 1912, durante sua viagem inaugural, o Titanic\n",
    "afundou depois de colidir com um iceberg, matando 1502 dos 2224 passageiros e tripulação a bordo. Esta grande tragédia chocou a comunidade internacional\n",
    "e levou a  maiores regulações de segurança para os navios.\n",
    "\n",
    "Uma das razões do acidente ter sido com tantas perdas foi por causa da falta de botes salva vidas suficientes para os passageiros e para a tripulação.\n",
    "Contudo, existiram alguns elementos de sorte envolvidos na sobrevivência do naufrágio, alguns grupos de pessoas tinham mais chance de sobreviver do que outras,\n",
    "como as mulheres, crianças e da alta classe.\n",
    "\n",
    "Neste desafio, nós pedimos que você complete a análise de quais tipos de pessoas tiveram mais chance de sobreviver. Em particular, nós pedimos que você aplique\n",
    "com as ferramentas de machine learning para prever quais passageiros sobreviveram a tragédia.\n",
    "\n",
    "Habilidades práticas:\n",
    "    \n",
    "    - Classificação Binária;\n",
    "    - Python e R básico;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2: Reunindo os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um conjunto de dados nos é deixado de mão beijada com dados de treino e teste dentro do desafio do Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 3: Preparando os dados para uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no passo 2, temos tudo já oferecido pelo kaggle, vamos para a próxima etapa. Portanto, os processos normais de manipulação de dados, como arquitetura de dados,\n",
    "governança e extração estão fora do escopo. Sendo assim, apenas os dados limpos nos interessam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Importando bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte está escrito em Python 3.x. As bibliotecas nos dão funcionalidades pré-definidas e muito úteis para realizar algumas tarefas necessárias. A ideia é porque escrever 10 linhas de código\n",
    "se você pode escrever apenas uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "pandas version: 0.25.1\n",
      "matplotlib version: 3.1.1\n",
      "NumPy version: 1.16.5\n",
      "SciPy version: 1.3.1\n",
      "IPython version: 7.8.0\n",
      "scikit-learn version: 0.21.3\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Carregnado pacotes\n",
    "import sys #acessando parametros do sistema. doc em https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #coleção de funções para processamento e análise de dados para ser utilizado com Python\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #coleção de funções para visualização científica e de publicação\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #pacote fundaental para computação científica\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #coleção de funções para computação científica e matemática avançada\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #para imprimir/visualizar os dataframes no Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #coleção de algoritmos de Machine Learning\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#bibliotecas mistas\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignorar avisos recorrentes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "# Em caso de erro, verifique se falta alguma biblioteca a instalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Carregando bibliotecas de modelagem de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós usaremos a popular biblioteca 'scikit-learn' para o desenvolvimento de nossos algoritmos de Machine Learning. No sklearn, os algoritmos são chamados de Estimadores (Estimators) e são implementados nas suas próprias classes. Para visualização dos dados, nós iremos utilizar as bibliotecas 'matplotlib' e 'seaborn'. Abaixo estão os passos para carregar estas classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmos de Modelagem mais comuns\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier #se der problema aqui, abre o prompt pelo Anaconda e digita 'pip install xgboost'\n",
    "\n",
    "#Helpers (são classes que auxiliam e provem certas funcionalidades)\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualização\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Configurando os padrões de Visualização (cor, tamanho, etc.)\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Conhecendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um passo de conhecimento dos dados. Conheça-os pelo primeiro nome e aprenda um pouco sobre eles. Como parecem \n",
    "(tipo de dados, valores), como parecem funcionar (variáveis independentes/atributos), qual é o seu objetivo (variável dependente/alvo). Tente explorar os dados para ficar familiarizado com eles, os seus campos e a sua importância.\n",
    "\n",
    "Para começar, nós vamos primeiramente importar nossos dados. Depois, nós usaremos as funções 'info()' e 'sample()', para ter uma rápida noção dos dados brutos e do tipo de variáveis que se apresentam (qualitativas ou quantitativas). Clique aqui para ir diretamente no desafio oficial do Kaggle: https://www.kaggle.com/c/titanic/data. Mas não é necessário perder muito tempo por lá, podes continuar o restante dos passos por aqui.\n",
    "\n",
    "Para um rápido resumo sobre os tipos de variáveis, se for necessário, acesse: http://leg.ufpr.br/~silvia/CE055/node8.html\n",
    "\n",
    "1. A variável 'Survived' (Sobreviventes) é a nossa variável dependente ou de resultado. É uma variável binária de tipo nominal, que apresenta dois possíveis estados: 1 para sobreviveu ('survived') e 0 para não-sobreviveu ('not survive'). Todas as outras variáveis são potenciais previsores ou variáveis independentes. É importante notar que quanto mais variáveis previsoras não torna o modelo melhor, mas sim, as variáveis corretamente escolhidas para tal.\n",
    "\n",
    "2. A variável 'PassengerID' e 'Ticket' são assumidas como identificadores randômicos, que não terão impatco para a nossa principal variável ('Survived'). Sendo assim, nós iremos excluí-las de nossa análise.\n",
    "\n",
    "3. A variável 'Pclass' é do tipo ordinal relacionado com a classe do ticket (passagem), uma representação do status socioeconomico do passageiro (em inglês, 'SES - Socioeconomic Status'), represetado com os números:\n",
    "1 - Classe Alta ('upper class')\n",
    "2 - Classe Média ('middle class')\n",
    "3 - Classe Baixa ('lower class')\n",
    "\n",
    "4. A variável 'Name' é do tipo nominal. Ela poderia ser utilizada para verificar o gênero do passageiro através dos pronomes de tratamento, tamanho da família através do sobrenome, e situação socioeconômica através dos título que iniciam o nome como doutor ou mestre. Como estas variáveis realmente existem, nós iremos fazer uso delas para verificar se o título de honra, como mestre/doutor, faz alguma diferença.\n",
    "\n",
    "5. As variáveis 'Sex' e 'Embarked', sexo e onde embarcou, são do tipo nominal. Elas serão convertidas para poderem ser utilizadas nos cálculos matemáticos.\n",
    "\n",
    "6. As variáveis 'Age' e 'Fare, idade e valor bilhete/passagem, são variáveis do tipo quantitativas contínuas. \n",
    "\n",
    "7. A variável 'SibSp' representa número de de irmãos/cônjuges relacionados a bordo e a variável 'Parch' representa o número de pais/filhos relacionados a bordo. Ambos são variáveis quantitativas discretas. Elas podem ser úteis para ter uma ideia do tamanho da família a bordo ou se o passageiro estava sozinho.\n",
    "\n",
    "8. A variável 'Cabin' é do tipo nominal que pode ser utilizada para aproximar a posição da cabine no navio, que dá uma ideia de onde estariam os passageiros na hora do incidente e também do status socioeconomico (mais em cima, melhor posicionado, alta classe). Contudo, como existem muitos valores nulos nesta coluna, não vai adicionar valor para a nossa análise e será excluída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importando os dados dos arquivos baixados:\n",
    "#documentacao sobre a função read = https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "#data_raw é a variavel que assume os valores da planilha-treino, lembrando que o desafio do Titanic no Kaggle nos proporciona\n",
    "#três arquivos: um para treino, que é o arquivo que faremos toda a análise e o modelo de previsão, também é disponibilizado\n",
    "#o arquivo de teste, que é o arquivo que testaremos o nosso modelo, e ainda existe um modelo ja pronto, que é o gender_submission,\n",
    "#que traz a solução 'todos homens morreram, todas as mulheres sobreviveram', que nos dá uma ideia de pontuação, colocando\n",
    "#este modelo pronto no site do kaggle, voce já tera uma nota de acurácia deste modelo simples, e que te dá a base de\n",
    "#nota mínima que você deve alcançar com o seu próprio modelo\n",
    "data_raw = pd.read_csv('train.csv') \n",
    "\n",
    "#um conjunto de dados (dataset) deve ser dividido em três: treino, teste e validação (train, test, and (final) validation)\n",
    "#o arquivo teste é o mesmo do arquivo de validaçao para esta competição específica\n",
    "#nós iremos dividir o arquivo treino em dois: dados de treino e dados de teste nas seções futuras\n",
    "data_val  = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "#criamos uma cópia ainda para poder manipular sem preocupação\n",
    "#lembrando de utilizar a forma mais adequada de cópia, com o parâmetro 'deep', utilizando a função 'copy'\n",
    "# maiores informações: https://stackoverflow.com/questions/46327494/python-pandas-dataframe-copydeep-false-vs-copydeep-true-vs\n",
    "data1 = data_raw.copy(deep = True)\n",
    "\n",
    "#passando os dois arquivos por referência é conveniente, porque nós podemos limpar ambos os datasets de uma só vez\n",
    "data_cleaner = [data1, data_val]\n",
    "\n",
    "\n",
    "#Visualizando os dados:\n",
    "\n",
    "#aqui nos dá uma ideia de quantos dados nulos temos, teremos que fazer um tratamento destes depois\n",
    "print (data_raw.info()) #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\n",
    "\n",
    "#os cinco primeiro registros\n",
    "data_raw.head() #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html\n",
    "\n",
    "#outra opção é pegar os 05 últimos registros\n",
    "#data_raw.tail() #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html\n",
    "\n",
    "#ainda podemos pegar uma amotra aleatória de 10 registros\n",
    "#data_raw.sample(10) #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21 Os 4 C's do tratamento de dados: correção, completude, criação e conversão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, nós iremos tratar os nossos dados fazendo 1) correção de valores excêntricos e 'outliers', 2) completando as informações faltantes, 3) criando novas ferramentas para análise, e 4) convertendo campos para o formato correto para os cálculos e apresentação.\n",
    "\n",
    "<h5>1. Correção</h5>\n",
    "Verificando os dados inicialmente, não parece haver nenhum dado fora do normal. Adicionalmente, nós podemos verificar potenciais 'outliers' nas colunas 'Age' e 'Fare'. Contudo, uma vez que são valores razoáveis, nós iremos esperar até depois de completar a nossa etapa de análise exploratória dos dados para, assim, determinar se nós deveremos incluí-los ou excluí-los do nosso dataset. Mas veja bem, se encontrássemos valores muito fora do padrão, como idade = 800 ao invés de 80, então é provável que faríamos a correção agora. Mas, nós temos que ter cuidado quando modificamos o valor original dos dados, porque temos que fazer um modelo acurado.\n",
    "\n",
    "<h5>2. Completude</h5>\n",
    "Existem valores nulos (NaN) ou valores perdidos nas categorias de 'Age', 'Cabin e 'Embarked', conforme verificamos anteriormente com o uso da função 'info()'. Valores perdidos pode ser algo ruim, porque alguns algoritmos não sabem como lidar com estes valores nulos e eles irão falhar. Enquanto outros, como o modelo de Árvores de Decisão, podem lidar com valores nulos. Portanto, é importante corrigir antes de nós começarmos a modelar os dados, porque nós iremos comparar e contrastar diversos modelos. Existem dois métodos comuns, ou deletando o registro ou dando a ele um valor razoável. Não é recomendado que se delete o registro, especialmente uma grande porcentagem de registros, a não ser que ele apresente um valor realmente incompleto. Como alternativa, é melhor atribuir os valores nulos. Uma metodologia básica para dados qualitativos é utilizar média, mediana, ou média + desvio padrão aleatório (mean, median or mean + randomized standard deviation). Uma metodologia intermediária é utilizar esta metodologia básica baseado em critérios específicos; como por exemplo, uma média de idade por classe ou porto de embarque por valor-ticket e status-socioeconômico. Existem metodologias mais complexas, contudo antes de utilizá-las, é necessário fazer uma comparação com o modelo mais básicopara determinar se esta complexidade vai adicionar valor. Para este dataset (conjunto de dados), no campo Idade ('Age') utilizaremos a mediana (median), o campo 'Cabin' vamos eliminar, e o Embarque ('Embark') iremos utilizar a moda (mode). Modelos subsequentes poderão modificar esta nossa decisão com o intuito de melhor a performance do modelo.\n",
    "\n",
    "<h5>3. Criação</h5>\n",
    "Engenharia de recursos (feature engineering) é quando nós utilizamos ferramentas/recursos para criar novas ferramentas para determinar se elas conseguirão novos indicadores para prever nosso resultado. Para este dataset, nós vamos criar uma ferramenta principal para determinar se ele desempenha algum papel na questão de indicar os sobreviventes.\n",
    "\n",
    "<h5>4. Conversão</h5>\n",
    "Por último, mas não menos importante, nós vamos lidar com a formatação. Não existem formatos de moeda ou data, mas formato 'datatype'. Nossos dados categóricos são importados como objetos, o que dificulta os cálculos matemáticos. Para este dataset, nós iremos converter estes objetos (object datatypes) para variáveis categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do arquivo de Treino com os valores nulos:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "----------\n",
      "Colunas de Teste/Validação com os valores nulos:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beane, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass               Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                891   891   \n",
       "unique          NaN         NaN         NaN                891     2   \n",
       "top             NaN         NaN         NaN  Beane, Mr. Edward  male   \n",
       "freq            NaN         NaN         NaN                  1   577   \n",
       "mean     446.000000    0.383838    2.308642                NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare    Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000      204   \n",
       "unique         NaN         NaN         NaN       681         NaN      147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  B96 B98   \n",
       "freq           NaN         NaN         NaN         7         NaN        4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208      NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429      NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000      NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400      NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200      NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000      NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Colunas do arquivo de Treino com os valores nulos:\\n', data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Colunas de Teste/Validação com os valores nulos:\\n', data_val.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22 Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que sabemos o que precisa ser limpo, vamos executar o nosso código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Documentação para conhecer as funções do pandas e do desenvolvimento que estão sendo utilizadas:</h5>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\">pandas.DataFrame</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\">pandas.DataFrame.info</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html\">pandas.DataFrame.describe</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/indexing.html\">Indexing and Selecting Data</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html\">pandas.isnull</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html\">pandas.DataFrame.sum</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mode.html\">pandas.DataFrame.mode</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html\">pandas.DataFrame.copy</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\">pandas.DataFrame.copy</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\">pandas.DataFrame.drop</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html\">pandas.Series.value_counts</a></li>\n",
    "<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html\">pandas.DataFrame.loc</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "----------\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###COMPLETUDE: completando ou deletando valores perdidos/nulos nos datasets 'treino' e 'teste/validação'\n",
    "for dataset in data_cleaner:    \n",
    "    #completando idades faltantes com o valor da mediana\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "\n",
    "    #completando os pontos-embarque com o valor da moda\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "    #completando os valores-ticket com a mediana\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n",
    "    \n",
    "#deletando a coluna 'Cabin' e as outras duas já mencionadas anteriormente: 'PassengerId' e 'Ticket' no dataset de treino apenas\n",
    "drop_column = ['PassengerId','Cabin', 'Ticket']\n",
    "data1.drop(drop_column, axis=1, inplace = True)\n",
    "\n",
    "print(data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n",
      "----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "Survived      891 non-null int64\n",
      "Pclass        891 non-null int64\n",
      "Name          891 non-null object\n",
      "Sex           891 non-null object\n",
      "Age           891 non-null float64\n",
      "SibSp         891 non-null int64\n",
      "Parch         891 non-null int64\n",
      "Fare          891 non-null float64\n",
      "Embarked      891 non-null object\n",
      "FamilySize    891 non-null int64\n",
      "IsAlone       891 non-null int64\n",
      "Title         891 non-null object\n",
      "FareBin       891 non-null category\n",
      "AgeBin        891 non-null category\n",
      "dtypes: category(2), float64(2), int64(6), object(4)\n",
      "memory usage: 85.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 16 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "FamilySize     418 non-null int64\n",
      "IsAlone        418 non-null int64\n",
      "Title          418 non-null object\n",
      "FareBin        418 non-null category\n",
      "AgeBin         418 non-null category\n",
      "dtypes: category(2), float64(2), int64(6), object(6)\n",
      "memory usage: 47.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Holm, Mr. John Fredrik Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pavlovic, Mr. Stefo</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hegarty, Miss. Hanora \"Nora\"</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mr. Dickinson H</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mr. Jacques Heath</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Reynaldo, Ms. Encarnacion</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Misc</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Naidenoff, Mr. Penko</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sirota, Mr. Maurice</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Horgan, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wright, Mr. George</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "818         0       3  Holm, Mr. John Fredrik Alexander    male  43.0      0   \n",
       "519         0       3               Pavlovic, Mr. Stefo    male  32.0      0   \n",
       "654         0       3      Hegarty, Miss. Hanora \"Nora\"  female  18.0      0   \n",
       "484         1       1           Bishop, Mr. Dickinson H    male  25.0      1   \n",
       "137         0       1       Futrelle, Mr. Jacques Heath    male  37.0      1   \n",
       "443         1       2         Reynaldo, Ms. Encarnacion  female  28.0      0   \n",
       "287         0       3              Naidenoff, Mr. Penko    male  22.0      0   \n",
       "837         0       3               Sirota, Mr. Maurice    male  28.0      0   \n",
       "613         0       3                  Horgan, Mr. John    male  28.0      0   \n",
       "555         0       1                Wright, Mr. George    male  62.0      0   \n",
       "\n",
       "     Parch     Fare Embarked  FamilySize  IsAlone Title          FareBin  \\\n",
       "818      0   6.4500        S           1        1    Mr   (-0.001, 7.91]   \n",
       "519      0   7.8958        S           1        1    Mr   (-0.001, 7.91]   \n",
       "654      0   6.7500        Q           1        1  Miss   (-0.001, 7.91]   \n",
       "484      0  91.0792        C           2        0    Mr  (31.0, 512.329]   \n",
       "137      0  53.1000        S           2        0    Mr  (31.0, 512.329]   \n",
       "443      0  13.0000        S           1        1  Misc   (7.91, 14.454]   \n",
       "287      0   7.8958        S           1        1    Mr   (-0.001, 7.91]   \n",
       "837      0   8.0500        S           1        1    Mr   (7.91, 14.454]   \n",
       "613      0   7.7500        Q           1        1    Mr   (-0.001, 7.91]   \n",
       "555      0  26.5500        S           1        1    Mr   (14.454, 31.0]   \n",
       "\n",
       "           AgeBin  \n",
       "818  (32.0, 48.0]  \n",
       "519  (16.0, 32.0]  \n",
       "654  (16.0, 32.0]  \n",
       "484  (16.0, 32.0]  \n",
       "137  (32.0, 48.0]  \n",
       "443  (16.0, 32.0]  \n",
       "287  (16.0, 32.0]  \n",
       "837  (16.0, 32.0]  \n",
       "613  (16.0, 32.0]  \n",
       "555  (48.0, 64.0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###CRIAÇÃO: engenharia de recursos para o dataset de treino e o teste/validação\n",
    "for dataset in data_cleaner:    \n",
    "    #Valores Discretos\n",
    "    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    dataset['IsAlone'] = 1 #inicializa como sim/1 para sozinho ('alone')\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # atualiza para n]ao/0 se o tamanho-familia > 1\n",
    "\n",
    "    #divisão rápida das partes dos nomes. Ver doc em http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "\n",
    "    #Variáveis Contínuas bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    #Fare (valor-ticket) Bins/Buckets usando qcut ou frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "\n",
    "    #Age (idade) Bins/Buckets usando cut ou valor bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n",
    "\n",
    "\n",
    "    \n",
    "#Limpando titulos raros nos nomes\n",
    "#print(data1['Title'].value_counts())\n",
    "stat_min = 10 #enquanto dizer o que é pequeno é um pouco arbitrario, nós usaremos o minimo comum em estatistica. Ver em http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (data1['Title'].value_counts() < stat_min) #isto irá criar uma série binaria(V ou F) com nome principal como índice\n",
    "\n",
    "#Funções 'apply' and 'lambda' são rápidos para limpar o código, encontrando e substituindo em poucas linhas de codigo\n",
    "#ver mais info em: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(data1['Title'].value_counts())\n",
    "print(\"-\"*10)\n",
    "\n",
    "\n",
    "#Vendo os dados novamente\n",
    "data1.info()\n",
    "data_val.info()\n",
    "data1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23 Convertendo Formatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós iremos converter os dados para variáveis binárias (existe/não existe; é/não-é; em inglês: dummy variables) para análise matemática. Existem múltiplos caminhos para codificar variáveis categóricas; nós utilizaremos o 'sklearn' e funções do 'pandas'.<\"\\n\">\n",
    "Neste passo, nós iremos ainda definir nosso 'x' (variavel de previsão/independente) e o 'y' (variavel dependente/alvo/resultado) que são nossas variáveis do modelo de dados.\n",
    "\n",
    "<h5>Documentação:</h5>\n",
    "<li>Categorical Encoding: http://pbpython.com/categorical-encoding.html</li>\n",
    "<li>Sklearn LabelEncoder: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html</li>\n",
    "<li>Sklearn OneHotEncoder: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html</li>\n",
    "<li>Pandas Categorical dtype: https://pandas.pydata.org/pandas-docs/stable/categorical.html</li>\n",
    "<li>pandas.get_dummies: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y:  ['Survived', 'Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
      "\n",
      "Bin X Y:  ['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code'] \n",
      "\n",
      "Dummy X Y:  ['Survived', 'Pclass', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch   Age     Fare  FamilySize  IsAlone  Sex_female  \\\n",
       "0       3      1      0  22.0   7.2500           2        0           0   \n",
       "1       1      1      0  38.0  71.2833           2        0           1   \n",
       "2       3      0      0  26.0   7.9250           1        1           1   \n",
       "3       1      1      0  35.0  53.1000           2        0           1   \n",
       "4       3      0      0  35.0   8.0500           1        1           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  \\\n",
       "0         1           0           0           1             0           0   \n",
       "1         0           1           0           0             0           0   \n",
       "2         0           0           0           1             0           0   \n",
       "3         0           0           0           1             0           0   \n",
       "4         1           0           0           1             0           0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  \n",
       "0           0         1          0  \n",
       "1           0         0          1  \n",
       "2           1         0          0  \n",
       "3           0         0          1  \n",
       "4           0         1          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVERSÃO: convertendo objetos para categorias usando 'Label Encoder' para o treino e o teste/validação\n",
    "\n",
    "#Codificando as categorias de dados\n",
    "label = LabelEncoder()\n",
    "for dataset in data_cleaner:    \n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n",
    "\n",
    "\n",
    "#definindo a variável y como target/outcome\n",
    "Target = ['Survived']\n",
    "\n",
    "#definindo a variável x como feature selection\n",
    "data1_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #nomes das categorias\n",
    "data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare'] #ajeitando um dataset para o cálculo\n",
    "data1_xy =  Target + data1_x\n",
    "print('Original X Y: ', data1_xy, '\\n')\n",
    "\n",
    "\n",
    "#definindo variáveis x das características originais com as binarias para remover as variáveis contínuas\n",
    "data1_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')\n",
    "\n",
    "\n",
    "#definindo x e y para as características binárias originais ('dummy features')\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
